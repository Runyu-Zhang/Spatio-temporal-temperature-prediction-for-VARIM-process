{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import itertools\n",
    "import os \n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "import PIL.Image as Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization, Flatten, Input, Dense,Dropout,Activation,Flatten,Reshape,Lambda,Embedding,Conv2D,MaxPooling2D, UpSampling2D   #卷积层，池化层\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow.python.platform.build_info as build \n",
    "import tensorflow_hub as hub \n",
    "import tensorflow_datasets as tfds \n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def getT0_all():\n",
    "  t0_filename = \"TEMPERATURE_at_frame240.txt\"  \n",
    "  time_stamp_raw = pd.read_csv(t0_filename, sep = '\\t', header = None, \n",
    "                                skiprows=[i for i in range(0,4)], on_bad_lines='skip')\n",
    "  timestamp = [float(s) for s in re.findall(r':\\s(.*)', time_stamp_raw.iat[2, 1])]\n",
    "  timestamp = timestamp[0]    # float number for timestamp\n",
    "    \n",
    "  temp_raw = pd.read_csv(t0_filename, header = None, sep = '\\t', \n",
    "                        skiprows=[i for i in range(0,9)]).iloc[[i for i in range(0, 17574-9)], [0, 1]]\n",
    "  temp_raw.columns = ['node_label', 'temperature']\n",
    "  temp = pd.merge(temp_raw, node_info, on = 'node_label')\n",
    "  temp['temperature'] = temp['temperature'] - 273.15\n",
    "\n",
    "  initial_time = 0\n",
    "  x_dim = (temp['node_x'].unique()).size;\n",
    "  y_dim = (temp['node_y'].unique()).size;\n",
    "  z_dim = (temp['node_z'].unique()).size;\n",
    "\n",
    "  temp['time'] = (timestamp - initial_time)/60    #time is in minutes\n",
    "  temp['scaled_x'] = ( temp['node_x'] / max(temp['node_x']) ) * x_dim\n",
    "  temp['scaled_y'] = ( (temp['node_y']) / (max(temp['node_y'])) ) * y_dim\n",
    "  temp['scaled_z'] = ( (temp['node_z']) / (max(temp['node_z'])) ) * z_dim\n",
    "\n",
    "  # cast original coordinates values into integers\n",
    "  temp['X'] = temp.scaled_x.astype('int');   \n",
    "  temp['Y'] = temp.scaled_y.astype('int');\n",
    "  temp['Z'] = temp.scaled_z.astype('int');\n",
    "  t0_info_all.append(temp)       ##### append current frame to info DF #####\n",
    "  \n",
    "  # cast temperature data into images\n",
    "  img_x = max(temp['X']) +1      \n",
    "  img_y = max(temp['Y']) +1      \n",
    "  img_z = max(temp['Z']) +1      \n",
    "  get_image = np.zeros(shape = (img_y, img_x, img_z))\n",
    "\n",
    "  for i in range(len(temp)):\n",
    "    x_coordinate = temp.loc[i, \"X\"]\n",
    "    y_coordinate = temp.loc[i, \"Y\"]\n",
    "    z_coordinate = temp.loc[i, \"Z\"]\n",
    "    get_image[y_coordinate][x_coordinate][z_coordinate] = temp.loc[i, \"temperature\"]\n",
    "  t0_img_all.append(get_image)   ##### append current frame to img DF #####\n",
    "\n",
    "def getInput(folder_name):   \n",
    "  input =[]\n",
    "  split_str = folder_name.split(\"_\")\n",
    "  input.append(split_str[2])\n",
    "  input.append(split_str[3])\n",
    "  input.append(split_str[4])\n",
    "  input.append(split_str[5])\n",
    "  return input\n",
    "\n",
    "def getImgChannel(channel, dataset):\n",
    "  output_img = []\n",
    "  length = len(dataset)\n",
    "  for i in range(length):\n",
    "    output_img.append(dataset[i, :, :, channel])\n",
    "  return np.array(output_img)\n",
    "\n",
    "def prep_Input_parameters(inputs):\n",
    "  dic0 = {'1': 41.0,  '2': 43.0,   '3': 44.0,  '4': 45.0,   '5': 46.0}\n",
    "  dic1 = {'1': 79.0,  '2': 80.0,  '3': 81.0,  '4': 82.0,  '5': 83.0}\n",
    "  dic2 = {'1': 79.0, '2': 80.0, '3': 81.0, '4': 82.0, '5': 83.0}\n",
    "  dic3 = {'1': 20.0,  '2': 21.0,  '3': 22.0,  '4': 23.0,  '5': 25.0}\n",
    "  new_inputs_all = []\n",
    "  for i in range(len(inputs)):\n",
    "    this_input = []\n",
    "    for j in range(len(inputs[i])):\n",
    "      the_value = (inputs[i])[j]\n",
    "      if j == 0:\n",
    "        this_input.append(dic0[the_value])\n",
    "      elif j == 1:\n",
    "        this_input.append(dic1[the_value])\n",
    "      elif j == 2:\n",
    "        this_input.append(dic2[the_value])\n",
    "      else:\n",
    "        this_input.append(dic3[the_value])\n",
    "        new_inputs_all.append(this_input)\n",
    "  return new_inputs_all\n",
    "\n",
    "def patch_image(dataset):\n",
    "  for img in range(len(dataset)):\n",
    "    for col in range(102):\n",
    "      (dataset[img])[28, col] = ((dataset[img])[27, col] + (dataset[img])[29, col]) / 2\n",
    "    for row in range(30):\n",
    "      (dataset[img])[row, 100] = ((dataset[img])[row, 99] + (dataset[img])[row, 101]) / 2\n",
    "    (dataset[img])[28, 100] = ((dataset[img])[27, 99] + (dataset[img])[27, 101] + (dataset[img])[29, 99] + (dataset[img])[29, 101]) / 4\n",
    "    for row1 in range(27, 30):\n",
    "        for col1 in range(99, 102):\n",
    "            (dataset[img])[row1, col1] = ((dataset[img])[row1, col1-1] + (dataset[img])[row1-1, col1]) / 2\n",
    "################################################################################\n",
    "%cd C:\\A4-21 3D model temperature control data set\n",
    "\n",
    "nodes_amt = 17574      # total nodes \n",
    "node_info = pd.read_csv('Mesh_3D_2m_0.56m_0.06m.txt', delim_whitespace = True, header = None)\n",
    "node_info.columns = ['node_label', 'node_x', 'node_y', 'node_z']\n",
    "node_info = node_info.astype(str).astype(float)\n",
    "\n",
    "root_dir = os.getcwd()\n",
    "folders = os.listdir(root_dir)\n",
    "\n",
    "input_parameters_all = []     # raw inputs for embeddings\n",
    "t0_img_all = []               # starting frame as output y for training\n",
    "t0_info_all = []\n",
    "\n",
    "num_parameters = 4            # not used yet\n",
    "temperature_info_all = []     # hold all temperature info of all datasets\n",
    "temperature_img_all = []      # hold all temperature imgs of all datasets\n",
    "\n",
    "for name in folders:\n",
    "  if (len(name)) == 20:\n",
    "    input_parameters_all.append(getInput(name))\n",
    "    cwd = \"C:/WindSTAR/A4-21 3D model temperature control data set/{}\".format(name)  \n",
    "    os.chdir(cwd)             # change directory \n",
    "    getT0_all()\n",
    "    \n",
    "# convert to Numpy array\n",
    "t0_img_all = np.array(t0_img_all)\n",
    "input_parameters_all = np.array(input_parameters_all)\n",
    "inputs_all = np.array(prep_Input_parameters(input_parameters_all))  # Convert parameters to real values\n",
    "\n",
    "All_img = []\n",
    "All_labels = []\n",
    "total_perm = 625\n",
    "\n",
    "for i in range(6):\n",
    "    which_layer = i\n",
    "    if(i == 5): which_layer = i + 1\n",
    "    current_layer_img = getImgChannel(which_layer, t0_img_all)\n",
    "    new_input = np.copy(inputs_all)\n",
    "    current_layer = np.full((total_perm, 1), i + 1)\n",
    "    new_input = np.hstack((new_input, current_layer))\n",
    "    for j in range(total_perm): \n",
    "        All_img.append(current_layer_img[j])\n",
    "        All_labels.append(new_input[j])\n",
    "        \n",
    "All_img = np.array(All_img)        #(3750, 30, 102)\n",
    "patch_image(All_img)\n",
    "All_img_norm = All_img / np.max(All_img)\n",
    "All_labels = np.array(All_labels)  #(3750, 30, 102)\n",
    "\n",
    "# normalize each column in the array labels\n",
    "max_val_labels = []\n",
    "min_val_labels = []\n",
    "for col in range(5):\n",
    "    max_val = np.max(All_labels[:,col])\n",
    "    min_val = np.min(All_labels[:,col])\n",
    "    max_val_labels.append(max_val)\n",
    "    min_val_labels.append(min_val)\n",
    "    All_labels[:,col] = (All_labels[:,col] - min_val) / (max_val - min_val)\n",
    "    \n",
    "max_val_labels = np.array(max_val_labels)\n",
    "min_val_labels = np.array(min_val_labels)\n",
    "\n",
    "X_train_all, X_test, y_train_all, y_test = train_test_split(All_labels, All_img_norm, \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "y_test = y_test.reshape(y_test.shape[0], y_test.shape[1], y_test.shape[2], 1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], y_train.shape[2], 1)\n",
    "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], y_val.shape[2], 1)\n",
    "# X_train.shape = (2400, 5)\n",
    "# X_test.shape = (750, 5)\n",
    "# X_val.shape = (600, 5)\n",
    "# y_train.shape = (2400, 30, 102, 1)\n",
    "# y_test.shape = (750, 30, 102, 1)\n",
    "# y_val.shape = (600, 30, 102, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "par_net = []\n",
    "input_par = Input(shape = (5,), name = 'Input') \n",
    "x = Reshape((1, 1, 5), name = 'reshape1')(input_par)\n",
    "x = UpSampling2D((2, 2), name = 'up1')(x)\n",
    "x = Conv2D(128, (3, 3), activation = 'relu', padding = 'same', name = 'conv1')(x)\n",
    "x = UpSampling2D((2, 2), name = 'up2')(x)\n",
    "x = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'conv2')(x)\n",
    "x = UpSampling2D((3, 3), name = 'up3')(x)\n",
    "x = Conv2D(32, (3, 3), activation = 'relu', name = 'conv3')(x)\n",
    "x = UpSampling2D((1, 2), name = 'up4')(x)\n",
    "x = Conv2D(16, (3, 3), activation = 'relu', name = 'conv4')(x)\n",
    "x = UpSampling2D((2, 3), name = 'up5')(x)\n",
    "x = Conv2D(16, (2, 3), activation = 'relu', name = 'conv5')(x)\n",
    "x = UpSampling2D((2, 2), name = 'up6')(x)\n",
    "par_net = Conv2D(1, (1, 3), activation = 'relu', name = 'conv6')(x)\n",
    "par_net = Model(input_par, par_net)\n",
    "par_net.summary()\n",
    "\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "epochs = 1500\n",
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 100, verbose = 2),\n",
    "             ModelCheckpoint('Par-net.h5', monitor = 'val_loss', save_best_only = True, verbose=0)]\n",
    "keras.backend.set_epsilon(1)\n",
    "par_net.compile(loss = 'mae', optimizer = keras.optimizers.Adam(learning_rate = lr),  \n",
    "                 metrics=['mape'])\n",
    "history = par_net.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, workers=8,\n",
    "                      use_multiprocessing = 1, callbacks = callbacks, \n",
    "                      validation_data = (X_val, y_val))\n",
    "\n",
    "plt.plot(history.history['mape'], label = 'Training data')\n",
    "plt.plot(history.history['val_mape'], label ='Validation data')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.ylim(0, 25)\n",
    "plt.legend(loc = 'upper right', borderaxespad = 0, frameon = False)\n",
    "font = {'family' : 'normal', 'weight' : 'normal', 'size'   : 14}\n",
    "plt.rc('font', **font)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fc252",
   "metadata": {},
   "outputs": [],
   "source": [
    "par_net_testing = par_net.evaluate(X_test, y_test, verbose = 2)\n",
    "par_net_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### Load the trained par-net model and compare predictions with original data\n",
    "\n",
    "def plot_images_comparison(original, predicted, mape, process_par_str):\n",
    "  fig, (ax1, ax2, ax3) = plt.subplots(nrows = 3, ncols=1, figsize=(8, 9), sharex = True)\n",
    "  plt.tight_layout(pad = 1)\n",
    "  ax1.set_title('Processing parameters: ' + \"\\n\" + 'T1 = ' + str(process_par_str[0]) + ' °C, ' + \n",
    "                'T2 = ' + str(process_par_str[1]) + ' °C, ' + \n",
    "                'T3 = ' + str(process_par_str[2]) + ' °C, ' + \n",
    "                'T4 = ' + str(process_par_str[3]) + ' °C, ' + \n",
    "                'layer ' + str(process_par_str[4]) + \n",
    "                \"\\n\" + \"\\n\" + 'True temperature (°C)', pad=11, fontsize = font_size)\n",
    "  im1 = ax1.imshow(original, cmap='jet', aspect='auto')\n",
    "\n",
    "  ax2.set_title('Predicted temperature (°C)', pad=11, fontsize = font_size)\n",
    "  im2 = ax2.imshow(predicted, cmap='jet', aspect='auto')\n",
    "\n",
    "  avg_MAPE = np.round_(np.sum(mape) / (mape.shape[0] * mape.shape[1]), decimals  = 2)\n",
    "  ax3.set_title('MAPE (%) mapping with average ' + str(round(avg_MAPE, 1)) + ' %', \n",
    "                pad=11, fontsize = font_size)\n",
    "  im3 = ax3.imshow(mape, cmap='jet', aspect='auto')\n",
    "  \n",
    "  #plt.setp(ax[0], xlabel='Length of composite (pixels)')\n",
    "  plt.setp(ax3, xlabel='Length of composite (pixels)')\n",
    "  plt.setp(ax2, ylabel='Width of composite (pixels)')\n",
    "\n",
    "  # add space for colour bar\n",
    "  fig.subplots_adjust(right = 0.86)\n",
    "  cbar_ax1 = fig.add_axes([0.89, 0.48, 0.01, 0.3])\n",
    "  cbar1_ticks = np.around(np.linspace(np.around(np.min(predicted), decimals = 1), \n",
    "                            np.around(np.max(predicted), decimals = 1), 6, endpoint=True), decimals = 1)\n",
    "  cbar1 = fig.colorbar(im2, cax = cbar_ax1)\n",
    "  cbar1.set_ticks(cbar1_ticks)\n",
    "  cbar1.set_ticklabels((np.around(cbar1_ticks, decimals = 0)).astype(int))\n",
    "  ax1.text(1.04, 0.55, '(°C)', transform=ax1.transAxes, fontsize = font_size, verticalalignment='top')\n",
    "\n",
    "  cbar_ax2 = fig.add_axes([0.89, 0.1, 0.01, 0.15])\n",
    "  cbar2_ticks = np.around(np.linspace(np.around(np.min(mape), decimals = 1), \n",
    "                            np.around(np.max(mape), decimals = 1), 4, endpoint=True), decimals = 1)\n",
    "  cbar2 = fig.colorbar(im3, cax = cbar_ax2)\n",
    "  cbar2.set_ticks(cbar2_ticks)\n",
    "  cbar2.set_ticklabels(cbar2_ticks)\n",
    "  ax2.text(1.04, -0.35, '(%)', transform=ax2.transAxes, fontsize = font_size, verticalalignment='top')\n",
    "\n",
    "  font = {'family': 'Times New Roman', 'weight': 'normal', 'size': font_size}\n",
    "  plt.rc('font', **font)\n",
    "\n",
    "def calculate_MAPE_mapping(ori_data, pred_data):\n",
    "  mape_mapping_all = []\n",
    "  row = ori_data[0].shape[0]\n",
    "  col = ori_data[0].shape[1]\n",
    "  for frame in range(len(ori_data)):\n",
    "    current_ori = ori_data[frame]\n",
    "    current_pred = pred_data[frame]\n",
    "    current_mape = np.zeros(shape = (row, col))\n",
    "    for y in range(row):\n",
    "      for x in range(col):\n",
    "        ori_val = current_ori[y][x]\n",
    "        pred_val = current_pred[y][x]\n",
    "        current_mape[y][x] = np.absolute(ori_val - pred_val) / (ori_val + 0.0000000001) * 100\n",
    "    mape_mapping_all.append(current_mape)\n",
    "  return np.array(mape_mapping_all)\n",
    "\n",
    "### main \n",
    "five_par_all_X = np.vstack([X_train, X_val, X_test])\n",
    "five_par_all_Y = np.vstack([y_train, y_val, y_test])\n",
    "Pred_array = par_net.predict(five_par_all_X, batch_size = 128)    \n",
    "Prediction_norm = Pred_array.reshape(Pred_array.shape[0], Pred_array.shape[1], Pred_array.shape[2])\n",
    "Prediction = Prediction_norm * np.max(All_img)\n",
    "original_img = five_par_all_Y * np.max(All_img)\n",
    "mape_mapping = calculate_MAPE_mapping(original_img, Prediction)\n",
    "\n",
    "##### Pick a input processing parameters to compare results \n",
    "\n",
    "whichStep = 2001\n",
    "factor_label = [5, 4, 4, 5, 5]\n",
    "base_label = [41, 79, 79, 20, 1]\n",
    "font_size = 24\n",
    "\n",
    "process_par_num = (five_par_all_X[whichStep] * factor_label + base_label).astype(int)\n",
    "mape_at_frame = mape_mapping[whichStep]\n",
    "the_pred = Prediction[whichStep]\n",
    "ori = original_img[whichStep]\n",
    "plot_images_comparison(ori, the_pred, mape_at_frame, process_par_num)\n",
    "avg_MAPE_test = []\n",
    "for i in range(len(mape_mapping)):\n",
    "    mape = mape_mapping[i]\n",
    "    avg_MAPE = np.round_(np.sum(mape) / (mape.shape[0] * mape.shape[1]), decimals  = 2)\n",
    "    avg_MAPE_test.append(avg_MAPE)\n",
    "avg_MAPE_test = np.array(avg_MAPE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, edges, bars = plt.hist(avg_MAPE_test, \n",
    "                               weights = np.ones(len(avg_MAPE_test)) / len(avg_MAPE_test),\n",
    "                               bins=[0, 5, 10, 30, 40, 50, 100])\n",
    "plt.text(-4.1, 1.05, '0.972', fontsize = 14, verticalalignment='top')\n",
    "plt.xlabel(\"MAPE of the prediction (%)\")\n",
    "plt.ylabel(\"Relative frequency\")\n",
    "plt.ylim([0, 1.06])\n",
    "plt.xticks(np.arange(0, 110, 10))\n",
    "plt.yticks(np.arange(0, 1.2, 0.2))\n",
    "font = {'family': 'normal', 'weight': 'normal', 'size': 14}\n",
    "plt.rc('font', **font)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Tensorflow 2.5)",
   "language": "python",
   "name": "tf-2.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
