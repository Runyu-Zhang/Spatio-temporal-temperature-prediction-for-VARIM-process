{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import itertools\n",
    "import os \n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, BatchNormalization, Flatten, Input, Dense,Dropout,Activation,Flatten,Reshape,Lambda,Embedding,Conv2D,MaxPooling2D, UpSampling2D   #卷积层，池化层\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow.python.platform.build_info as build \n",
    "import tensorflow_hub as hub \n",
    "import tensorflow_datasets as tfds \n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "%cd C:\\...\n",
    "\n",
    "################################################################################\n",
    "\n",
    "def getTemp(starting_frame, ending_frame, info_current_dataset, img_current_dataset):\n",
    "  for frame in range(starting_frame, ending_frame + 1):\n",
    "    temp_filename = \"TEMPERATURE_at_frame%d.txt\" % frame \n",
    "    time_stamp_raw = pd.read_csv(temp_filename, sep='\\t', header=None, \n",
    "                                skiprows=[i for i in range(0,4)], on_bad_lines='skip')\n",
    "    timestamp = [float(s) for s in re.findall(r':\\s(.*)', time_stamp_raw.iat[2, 1])]\n",
    "    timestamp = timestamp[0]    \n",
    "      \n",
    "    temp_raw = pd.read_csv(temp_filename, header=None, sep='\\t', \n",
    "                          skiprows=[i for i in range(0,9)]).iloc[[i for i in range(0, 17583 - 9)], [0, 1]]\n",
    "    temp_raw.columns = ['node_label', 'temperature']\n",
    "    temp = pd.merge(temp_raw, node_info, on = 'node_label')\n",
    "    temp['step'] = frame\n",
    "    temp['temperature'] = temp['temperature'] - 273.15\n",
    "\n",
    "    if (frame == starting_frame):\n",
    "      initial_time = timestamp\n",
    "      x_dim = (temp['node_x'].unique()).size\n",
    "      y_dim = (temp['node_y'].unique()).size\n",
    "      z_dim = (temp['node_z'].unique()).size\n",
    "\n",
    "    temp['time'] = (timestamp - initial_time)/60   \n",
    "    temp['scaled_x'] = ( temp['node_x'] / max(temp['node_x']) ) * x_dim\n",
    "    temp['scaled_y'] = ( (temp['node_y']) / (max(temp['node_y'])) ) * y_dim\n",
    "    temp['scaled_z'] = ( (temp['node_z']) / (max(temp['node_z'])) ) * z_dim\n",
    "\n",
    "    temp['X'] = temp.scaled_x.astype('int')\n",
    "    temp['Y'] = temp.scaled_y.astype('int')\n",
    "    temp['Z'] = temp.scaled_z.astype('int')\n",
    "    info_current_dataset.append(temp)                     # append current frame\n",
    "    \n",
    "    img_x = max(temp['X']) + 1   # 102\n",
    "    img_y = max(temp['Y']) + 1   # 30 \n",
    "    img_z = max(temp['Z']) + 1   # 6  \n",
    "\n",
    "    get_image = np.zeros(shape = (img_y, img_x, img_z))\n",
    "\n",
    "    for i in range(len(temp)):\n",
    "      x_coordinate = temp.loc[i, \"X\"]\n",
    "      y_coordinate = temp.loc[i, \"Y\"]\n",
    "      z_coordinate = temp.loc[i, \"Z\"]\n",
    "      get_image[y_coordinate][x_coordinate][z_coordinate] = temp.loc[i, \"temperature\"]\n",
    "    img_current_dataset.append(get_image)                 # append current frame\n",
    " \n",
    "def getImgChannel(channel, dataset):\n",
    "  output_img = []\n",
    "  length = len(dataset)\n",
    "  for i in range(length):\n",
    "    output_img.append(dataset[i, :, :, channel])\n",
    "  return np.array(output_img)\n",
    "\n",
    "def get_all_ImgChannel(dataset):\n",
    "  output_img = []\n",
    "  length = len(dataset)\n",
    "  for i in range(length):\n",
    "    output_img.append(dataset[i, :, :, 0])\n",
    "  for i in range(length):\n",
    "    output_img.append(dataset[i, :, :, 1])\n",
    "  for i in range(length):\n",
    "    output_img.append(dataset[i, :, :, 2])\n",
    "  for i in range(length):\n",
    "    output_img.append(dataset[i, :, :, 3])\n",
    "  for i in range(length):\n",
    "    output_img.append(dataset[i, :, :, 4])\n",
    "  for i in range(length):\n",
    "    output_img.append(dataset[i, :, :, 6])\n",
    "  return np.array(output_img)\n",
    "\n",
    "def patch_image(dataset):\n",
    "  for img in range(len(dataset)):\n",
    "    for col in range(102):\n",
    "      (dataset[img])[28, col] = ((dataset[img])[27, col] + (dataset[img])[29, col]) / 2\n",
    "    for row in range(30):\n",
    "      (dataset[img])[row, 100] = ((dataset[img])[row, 99] + (dataset[img])[row, 101]) / 2\n",
    "    (dataset[img])[28, 100] = ((dataset[img])[27, 99] + (dataset[img])[27, 101] + (dataset[img])[29, 99] + (dataset[img])[29, 101]) / 4\n",
    "\n",
    "################################################################################\n",
    "node_info = pd.read_csv('Mesh_info.txt', delim_whitespace=True, header=None)\n",
    "node_info.columns = ['node_label', 'node_x', 'node_y', 'node_z']\n",
    "node_info = node_info.astype(str).astype(float)\n",
    "\n",
    "temperature_info_all = [] \n",
    "temperature_img_all = []\n",
    "\n",
    "getTemp(1, 541, temperature_info_all, temperature_img_all)\n",
    "\n",
    "temperature_img_all_array = np.array(temperature_img_all)\n",
    "\n",
    "layer_z6 = getImgChannel(6, temperature_img_all_array)\n",
    "patch_image(layer_z6)\n",
    "layer_z6_norm = layer_z6 / np.max(layer_z6)\n",
    "max_temp = np.max(layer_z6)\n",
    "\n",
    "images_all_layers = get_all_ImgChannel(temperature_img_all_array)\n",
    "patch_image(images_all_layers)\n",
    "images_all_layers_norm = images_all_layers / np.max(images_all_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train = []\n",
    "\n",
    "# split into test and training datasets\n",
    "test_size = 0.2\n",
    "ratio = int((1 - test_size) * layer_z6_norm.shape[0])\n",
    "training_dataset = layer_z6_norm[:ratio]\n",
    "testing_dataset = layer_z6_norm[ratio:]\n",
    "\n",
    "ratio_sub = int((1 - test_size) * training_dataset.shape[0])\n",
    "train1 = training_dataset[:ratio_sub]\n",
    "test1 = training_dataset[ratio_sub:]\n",
    "\n",
    "train = train1.reshape(train1.shape[0], train1.shape[1] * train1.shape[2])\n",
    "validation = test1.reshape(test1.shape[0], test1.shape[1] * test1.shape[2])\n",
    "test = testing_dataset.reshape(testing_dataset.shape[0], testing_dataset.shape[1] * testing_dataset.shape[2])\n",
    "\n",
    "train_X, validation_X, test_X = train, validation, test;\n",
    "train_X = train_X.reshape(train_X.shape[0], 30, 102, 1);\n",
    "validation_X = validation_X.reshape(validation_X.shape[0], 30, 102, 1);\n",
    "test_X = test_X.reshape(test_X.shape[0], 30, 102, 1);\n",
    "\n",
    "#################################################################################################################################\n",
    "# GET TRAINED CNN autoencoder\n",
    "\n",
    "autoencoder = tf.keras.models.load_model('C:/Users/trained_CNN')\n",
    "encoder = Model(inputs = autoencoder.input, outputs = autoencoder.layers[8].output)\n",
    "\n",
    "deep_X_train = encoder.predict(train_X)\n",
    "deep_X_validation = encoder.predict(validation_X)\n",
    "deep_X_test = encoder.predict(test_X)\n",
    "\n",
    "deep_scalar = MinMaxScaler().fit(deep_X_train)\n",
    "deep_X_train = np.array(pd.DataFrame(deep_scalar.transform(deep_X_train)))\n",
    "deep_X_validation = np.array(pd.DataFrame(deep_scalar.transform(deep_X_validation)))\n",
    "deep_X_test = np.array(pd.DataFrame(deep_scalar.transform(deep_X_test)))\n",
    "\n",
    "def get_Time_Step_Data(time_step, data):\n",
    "  dataArray = []\n",
    "  for i in range(len(data) - time_step):  \n",
    "    tempArray = []\n",
    "    for j in range(time_step):\n",
    "      tempArray.append(data[i + j])\n",
    "    dataArray.append(tempArray)\n",
    "  return np.array(dataArray)\n",
    "\n",
    "TIME_STEP = 5\n",
    "\n",
    "RNN_Y_train = deep_X_train[TIME_STEP:]\n",
    "RNN_X_train = get_Time_Step_Data(TIME_STEP, deep_X_train)\n",
    "RNN_Y_validation = deep_X_validation[TIME_STEP:]\n",
    "RNN_X_validation = get_Time_Step_Data(TIME_STEP, deep_X_validation)\n",
    "RNN_Y_test = deep_X_test[TIME_STEP:]\n",
    "RNN_X_test = get_Time_Step_Data(TIME_STEP, deep_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#**************************** RNN MODEL training ************************\n",
    "rnn_hidden_units = 15\n",
    "lr = 0.001\n",
    "epoch = 1000\n",
    "batch_size = 12\n",
    "\n",
    "############ 128 DEEP FEATURES, RNN SETUP #####################\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate = lr, beta_1 = 0.9, beta_2 = 0.999, \n",
    "                            epsilon = None, decay = 0.000, amsgrad = False)\n",
    "RNN_model = keras.Sequential()\n",
    "\n",
    "RNN_model.add(layers.SimpleRNN(rnn_hidden_units, activation = 'softsign' ,\n",
    "                    input_shape = (RNN_X_train.shape[1], RNN_X_train.shape[2]),\n",
    "                    return_sequences = 1))\n",
    "RNN_model.add(layers.SimpleRNN(30, activation = 'tanh', return_sequences=0))\n",
    "RNN_model.add(layers.Dense(128))\n",
    "\n",
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 100, verbose=2),\n",
    "             ModelCheckpoint('RNN777.h5', monitor = 'val_loss', save_best_only = True, verbose = 0)]\n",
    "keras.backend.set_epsilon(1)\n",
    "RNN_model.compile(loss = 'mae', optimizer = opt, metrics=['mape'])\n",
    "RNN_model_history = RNN_model.fit(RNN_X_train, RNN_Y_train, epochs = epoch, callbacks = callbacks,\n",
    "                        batch_size = batch_size, verbose = 1, shuffle = True,\n",
    "                        validation_data = (RNN_X_validation, RNN_Y_validation))\n",
    "\n",
    "plt.plot(RNN_model_history.history['mape'], label='Training data')\n",
    "plt.plot(RNN_model_history.history['val_mape'], label ='Validation data')\n",
    "plt.ylabel('MAPE')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model_testing = RNN_model.evaluate(RNN_X_test, RNN_Y_test, verbose = 2)\n",
    "RNN_model_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3276,
     "status": "ok",
     "timestamp": 1659642605308,
     "user": {
      "displayName": "Tommy Zheng",
      "userId": "08631987435852587796"
     },
     "user_tz": 300
    },
    "id": "z36pe4boZ0BS",
    "outputId": "ea0fa87f-ca7c-4d66-bb86-90374155642e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#####################################################################################\n",
    "################ MAKE PREDICTIONS BASED ON TRAINED MODEL ############################\n",
    "#### Load the trained LSTM and RNN models\n",
    "\n",
    "RNN_file = 'C:/trained_RNN'\n",
    "RNN_model = tf.keras.models.load_model(RNN_file)\n",
    "LSTM_file = 'C:/trained_LSTM'\n",
    "LSTM_model = tf.keras.models.load_model(LSTM_file)\n",
    "########################  Decoder ########################\n",
    "features = 128 \n",
    "deep_pred = Input(shape=(features, ))\n",
    "x = Reshape((1, 1, features), name = 'D1')(deep_pred)\n",
    "x = UpSampling2D((2, 2), name = 'D2')(x)\n",
    "x = Conv2D(64, (3, 3), activation = 'relu', padding = 'same', name = 'D3')(x)\n",
    "x = UpSampling2D((2, 2), name = 'D4')(x)\n",
    "x = Conv2D(32, (3, 3), activation = 'relu', padding = 'same', name = 'D5')(x)\n",
    "x = UpSampling2D((3, 3), name = 'D6')(x)\n",
    "x = Conv2D(16, (3, 3), activation = 'relu', name = 'D7')(x)\n",
    "x = UpSampling2D((3, 3), name = 'D8')(x)\n",
    "x = Conv2D(16, (1, 3), activation = 'relu', name = 'D9')(x)\n",
    "x = Conv2D(16, (1, 3), activation = 'relu', name = 'D10')(x)\n",
    "x = UpSampling2D((1, 4), name = 'D11')(x)\n",
    "decoded = Conv2D(1, (1, 3), activation = 'relu', name = 'D12')(x)\n",
    "decoder = Model(deep_pred, decoded)\n",
    "# decoder.summary()\n",
    "decoder.layers[3].set_weights([autoencoder.layers[11].get_weights()[0], \n",
    "                               autoencoder.layers[11].get_weights()[1]])\n",
    "decoder.layers[5].set_weights([autoencoder.layers[13].get_weights()[0],\n",
    "                               autoencoder.layers[13].get_weights()[1]])\n",
    "decoder.layers[7].set_weights([autoencoder.layers[15].get_weights()[0],\n",
    "                               autoencoder.layers[15].get_weights()[1]])\n",
    "decoder.layers[9].set_weights([autoencoder.layers[17].get_weights()[0],\n",
    "                               autoencoder.layers[17].get_weights()[1]])\n",
    "decoder.layers[10].set_weights([autoencoder.layers[18].get_weights()[0],\n",
    "                                autoencoder.layers[18].get_weights()[1]])\n",
    "decoder.layers[12].set_weights([autoencoder.layers[20].get_weights()[0],\n",
    "                                autoencoder.layers[20].get_weights()[1]])\n",
    "\n",
    "predict_RNN_all = []\n",
    "predict_LSTM_all = []\n",
    "\n",
    "for i in range(6):\n",
    "    Deep_temporal_current_layer = Deep_temporal_X_all[i]\n",
    "    max_temp = max_temp_all[i]\n",
    "    \n",
    "    LSTM_predict_hat = LSTM_model.predict(Deep_temporal_current_layer, batch_size = 32)    \n",
    "    RNN_predict_hat = RNN_model.predict(Deep_temporal_current_layer, batch_size = 32)    \n",
    "    \n",
    "    def deep_i2r(yp):\n",
    "        yr = deep_scalar.inverse_transform(yp.reshape(-1, features)) # 128 features\n",
    "        return yr\n",
    "    LSTM_deep_pred = deep_i2r(LSTM_predict_hat)\n",
    "    RNN_deep_pred = deep_i2r(RNN_predict_hat)\n",
    "\n",
    "    Pred_norm_LSTM = decoder.predict(LSTM_deep_pred)\n",
    "    Pred_norm_RNN = decoder.predict(RNN_deep_pred)\n",
    "\n",
    "    Pred_LSTM = max_temp * (Pred_norm_LSTM.reshape(Pred_norm_LSTM.shape[0], \n",
    "                                                         Pred_norm_LSTM.shape[1], \n",
    "                                                         Pred_norm_LSTM.shape[2]))\n",
    "    Pred_RNN = max_temp * (Pred_norm_RNN.reshape(Pred_norm_RNN.shape[0], \n",
    "                                                       Pred_norm_RNN.shape[1], \n",
    "                                                       Pred_norm_RNN.shape[2]))\n",
    "    predict_LSTM_all.append(Pred_LSTM)\n",
    "    predict_RNN_all.append(Pred_RNN)\n",
    "    \n",
    "predict_LSTM_all = np.array(predict_LSTM_all)\n",
    "predict_RNN_all = np.array(predict_RNN_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "error",
     "timestamp": 1657051525670,
     "user": {
      "displayName": "sarah eddin",
      "userId": "00587873946404513602"
     },
     "user_tz": 300
    },
    "id": "ypfUaCNf35HE",
    "outputId": "ffa6e765-e8c9-492f-b584-23b7c391278f"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def calculate_percent_MAPE_at_each_point(ori_data, pred_data):\n",
    "  row = ori_data.shape[0]\n",
    "  col = ori_data.shape[1]\n",
    "  mae = np.zeros(shape = (row, col))\n",
    "  for y in range(row):\n",
    "    for x in range(col):\n",
    "      ori_val = ori_data[y][x]\n",
    "      pred_val = pred_data[y][x]\n",
    "      mae[y][x] = np.absolute(ori_val - pred_val) / ori_val * 100\n",
    "  return mae\n",
    "\n",
    "############################## MAIN FUNCTION #############################\n",
    "x_time = []\n",
    "x_step = []\n",
    "accuracy_LSTM = []\n",
    "accuracy_RNN = []\n",
    "accuracy_2D_calculate_each_point_LSTM_all = []\n",
    "accuracy_1D_avg_calculate_each_point_LSTM_all = []\n",
    "accuracy_2D_calculate_each_point_RNN_all = []\n",
    "accuracy_1D_avg_calculate_each_point_RNN_all = []\n",
    "TIME_STEP = 5\n",
    "\n",
    "for which_layer in range(6):\n",
    "    layer_z6 = layer_img_all[which_layer]\n",
    "    Prediction_lstm = predict_LSTM_all[which_layer]\n",
    "    Prediction_rnn = predict_RNN_all[which_layer]\n",
    "    \n",
    "    accuracy_2D_calculate_each_point_LSTM = []\n",
    "    accuracy_1D_avg_calculate_each_point_LSTM = []\n",
    "    accuracy_2D_calculate_each_point_RNN = []\n",
    "    accuracy_1D_avg_calculate_each_point_RNN = []\n",
    "    \n",
    "    end_frame = 536\n",
    "    for step in range(0, end_frame, 1):\n",
    "      time = (temperature_info_all[TIME_STEP + step])['time'].iloc[0]\n",
    "      ori = layer_z6[TIME_STEP + step]\n",
    "      the_pred_LSTM = Prediction_lstm[step]\n",
    "      the_pred_RNN = Prediction_rnn[step]\n",
    "    \n",
    "      # Ploting\n",
    "      #plot_images_comparison(ori, the_pred, time)\n",
    "      the_pred_MAE_LSTM = the_pred_LSTM.reshape(the_pred_LSTM.shape[0] * the_pred_LSTM.shape[1])\n",
    "      the_pred_MAE_RNN = the_pred_RNN.reshape(the_pred_RNN.shape[0] * the_pred_RNN.shape[1])\n",
    "      ori_cal_MAE_ = ori.reshape(ori.shape[0] * ori.shape[1])\n",
    "      \n",
    "      if(which_layer == 5):\n",
    "        x_time.append(time)\n",
    "        x_step.append(step)\n",
    "\n",
    "      # Calculate percentage MAE at each point in each frame\n",
    "      the_result_LSTM = calculate_percent_MAPE_at_each_point(ori, the_pred_LSTM)\n",
    "      accuracy_2D_calculate_each_point_LSTM.append(the_result_LSTM)\n",
    "      accuracy_1D_avg_calculate_each_point_LSTM.append(np.average(the_result_LSTM))\n",
    "\n",
    "      the_result_RNN = calculate_percent_MAPE_at_each_point(ori, the_pred_RNN)\n",
    "      accuracy_2D_calculate_each_point_RNN.append(the_result_RNN)\n",
    "      accuracy_1D_avg_calculate_each_point_RNN.append(np.average(the_result_RNN))\n",
    "\n",
    "    accuracy_2D_calculate_each_point_LSTM_all.append(accuracy_2D_calculate_each_point_LSTM)\n",
    "    accuracy_1D_avg_calculate_each_point_LSTM_all.append(accuracy_1D_avg_calculate_each_point_LSTM)\n",
    "    accuracy_2D_calculate_each_point_RNN_all.append(accuracy_2D_calculate_each_point_RNN)\n",
    "    accuracy_1D_avg_calculate_each_point_RNN_all.append(accuracy_1D_avg_calculate_each_point_RNN)\n",
    "\n",
    "accuracy_1D_avg_calculate_each_point_LSTM_all = np.array(accuracy_1D_avg_calculate_each_point_LSTM_all)\n",
    "accuracy_1D_avg_calculate_each_point_RNN_all = np.array(accuracy_1D_avg_calculate_each_point_RNN_all)\n",
    "accuracy_2D_calculate_each_point_LSTM_all = np.array(accuracy_2D_calculate_each_point_LSTM_all)\n",
    "accuracy_2D_calculate_each_point_RNN_all = np.array(accuracy_2D_calculate_each_point_RNN_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time  \n",
    "##### PLOT CONTOUR COLORMAP TO COMPARE PREDICTION RESULTS WITH THE ORIGINAL IMAGES #####\n",
    "def plot_images_comparison(original, predicted, mape, mape_value, atTime, which_layer):\n",
    "  fig, (ax1, ax2, ax3) = plt.subplots(nrows = 3, ncols=1, figsize=(8, 9), sharex = True)\n",
    "  plt.tight_layout(pad = 1)\n",
    "  ax1.set_title('Layer ' + str(which_layer+1) + ' at ' + str(round(atTime, 0)) + ' mins: ' + \"\\n\" + \"\\n\" + \n",
    "                     'True temperature (°C)', pad=11, fontsize = font_size)\n",
    "  im1 = ax1.imshow(original, cmap='jet', aspect='auto')\n",
    "\n",
    "  ax2.set_title('CNN-RNN predicted temperature (°C)', pad = 11, fontsize = font_size)\n",
    "  im2 = ax2.imshow(predicted, cmap='jet', aspect='auto')\n",
    "\n",
    "  ax3.set_title('MAPE (%) mapping with average ' + str(round(mape_value, 1)) + ' %', pad=11, fontsize = font_size)\n",
    "  im3 = ax3.imshow(mape, cmap='jet', aspect='auto')\n",
    "  \n",
    "  #plt.setp(ax[0], xlabel='Length of composite (pixels)')\n",
    "  plt.setp(ax3, xlabel='Length of composite (pixels)')\n",
    "  plt.setp(ax2, ylabel='Width of composite (pixels)')\n",
    "\n",
    "  fig.subplots_adjust(right = 0.86)\n",
    "  cbar_ax1 = fig.add_axes([0.89, 0.48, 0.01, 0.3])\n",
    "  cbar1_ticks = np.around(np.linspace(np.around(np.min(predicted), decimals = 1), \n",
    "                            np.around(np.max(predicted), decimals = 1), 6, endpoint=True), decimals = 1)\n",
    "  cbar1 = fig.colorbar(im2, cax = cbar_ax1)\n",
    "  cbar1.set_ticks(cbar1_ticks)\n",
    "  cbar1.set_ticklabels((np.around(cbar1_ticks, decimals = 0)).astype(int))\n",
    "  ax1.text(1.04, 0.55, '(°C)', transform=ax1.transAxes, fontsize = font_size, verticalalignment='top')\n",
    "\n",
    "  cbar_ax2 = fig.add_axes([0.89, 0.1, 0.01, 0.15])\n",
    "  cbar2_ticks = np.around(np.linspace(np.around(np.min(mape), decimals = 1), \n",
    "                            np.around(np.max(mape), decimals = 1), 4, endpoint=True), decimals = 1)\n",
    "  cbar2 = fig.colorbar(im3, cax = cbar_ax2)\n",
    "  cbar2.set_ticks(cbar2_ticks)\n",
    "  cbar2.set_ticklabels(cbar2_ticks)\n",
    "  ax2.text(1.04, -0.35, '(%)', transform=ax2.transAxes, fontsize = font_size, verticalalignment='top')\n",
    "\n",
    "  font = {'family': 'Times New Roman', 'weight': 'normal', 'size': font_size}\n",
    "  plt.rc('font', **font)\n",
    "##########################################################################\n",
    "############################# DRIVER PROGRAM RNN PREDICTION RESULTS#############################\n",
    "which_layer = 2\n",
    "whichStep = 150\n",
    "font_size = 24\n",
    "this_layer = layer_img_all[which_layer]\n",
    "\n",
    "ori_IMG = this_layer[TIME_STEP + whichStep]\n",
    "pred_IMG = predict_RNN_all[which_layer, whichStep]\n",
    "mape_IMG = accuracy_2D_calculate_each_point_RNN_all[which_layer, whichStep]\n",
    "mape_at_frame = accuracy_1D_avg_calculate_each_point_RNN_all[which_layer, whichStep]\n",
    "time_ = ((temperature_info_all[TIME_STEP + whichStep])['time'].iloc[0]).astype('int')\n",
    "plot_images_comparison(ori_IMG, pred_IMG, mape_IMG, mape_at_frame, time_, which_layer)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sarah's RNN for Runyu.ipynb",
   "provenance": [
    {
     "file_id": "1IFplAQ0sg_19aD0ukIN_ZbJeSAjY_Snt",
     "timestamp": 1659715618081
    },
    {
     "file_id": "1cl3HRbHFEyv2gaHySl5aSp0YvSeDeZhT",
     "timestamp": 1657052325746
    },
    {
     "file_id": "1Zt9vabTTCqJ7cNkknI78aI4CHqnDbgJT",
     "timestamp": 1656013156148
    },
    {
     "file_id": "1rNwtnA5gjzw1PFR4uT46eWOJsABieiBL",
     "timestamp": 1655825490113
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9 (Tensorflow 2.5)",
   "language": "python",
   "name": "tf-2.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
